---
apiVersion: v1
kind: Service
metadata:
  name: inference-split-ondevice-final
  namespace: sparse
  labels:
    app: inference-split-ondevice-final
spec:
  ports:
  - port: 50007
    protocol: TCP
  selector:
    app: inference-split-ondevice-final

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-split-ondevice-final
  namespace: sparse
  labels:
    app: inference-split-ondevice-final
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: inference-split-ondevice-final
  template:
    metadata:
      labels:
        app: inference-split-ondevice-final
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: sparse/node
                operator: In
                values:
                - final
                - aio
      containers:
      - name: inference-split-ondevice-final
        image: split_inference
        imagePullPolicy: IfNotPresent
        env:
        - name: WORKER_LISTEN_ADDRESS
          value: "0.0.0.0"
        command: ["python3"]
        args: ["benchmark.py", "--suite", "offload_final", "--model", "VGG_server", "--dataset", "Imagenet100"]
        volumeMounts:
        - name: app-code
          mountPath: /app
        - name: sparse-code
          mountPath: /usr/lib/sparse_framework
        - name: sparse-data
          mountPath: /data
        - name: sparse-run
          mountPath: /run/sparse
      volumes:
      - name: app-code
        hostPath:
          path: /opt/sparse/examples/split_inference
      - name: sparse-code
        hostPath:
          path: /opt/sparse/sparse_framework
      - name: sparse-data
        hostPath:
          path: /var/lib/sparse/data
      - name: sparse-run
        hostPath:
          path: /mnt/sparse/run
---
apiVersion: batch/v1
kind: Job
metadata:
  name: inference-split-ondevice-client
  namespace: sparse
  labels:
    app: inference-split-ondevice-client
spec:
  template:
    metadata:
      labels:
        app: inference-split-ondevice-client
    spec:
      restartPolicy: Never
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: sparse/node
                operator: In
                values:
                - client
                - aio
      containers:
      - name: inference-split-ondevice-client
        image: split_inference
        imagePullPolicy: IfNotPresent
        env:
        - name: MASTER_UPSTREAM_HOST
          value: "inference-split-ondevice-final"
        command: ["python3"]
        args: ["benchmark.py", "--suite", "offload_client", "--model", "VGG_client"]
        volumeMounts:
        - name: app-code
          mountPath: /app
        - name: sparse-code
          mountPath: /usr/lib/sparse_framework
        - name: sparse-data
          mountPath: /data
        - name: sparse-run
          mountPath: /run/sparse
      volumes:
      - name: app-code
        hostPath:
          path: /opt/sparse/examples/split_inference
      - name: sparse-code
        hostPath:
          path: /opt/sparse/sparse_framework
      - name: sparse-data
        hostPath:
          path: /var/lib/sparse/data
      - name: sparse-run
        hostPath:
          path: /run/sparse

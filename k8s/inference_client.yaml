---
apiVersion: batch/v1
kind: Job
metadata:
  name: inference-client
  namespace: sparse
  labels:
    app: inference-client
spec:
  template:
    metadata:
      labels:
        app: inference-client
    spec:
      restartPolicy: Never
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: sparse/node
                operator: In
                values:
                - datasource
                - aio
      containers:
      - name: inference-client
        image: split_inference
        imagePullPolicy: IfNotPresent
        env:
        - name: MASTER_UPSTREAM_HOST
          value: "inference-worker"
        command: ["python3"]
        args: ["inference_client.py", "--model", "VGG_client"]
        volumeMounts:
        - name: app-code
          mountPath: /app
        - name: sparse-code
          mountPath: /usr/lib/sparse_framework
        - name: sparse-data
          mountPath: /data
        - name: sparse-run
          mountPath: /run/sparse
      volumes:
      - name: app-code
        hostPath:
          path: /opt/sparse/examples/split_inference
      - name: sparse-code
        hostPath:
          path: /opt/sparse/sparse_framework
      - name: sparse-data
        hostPath:
          path: /var/lib/sparse/data
      - name: sparse-run
        hostPath:
          path: /run/sparse

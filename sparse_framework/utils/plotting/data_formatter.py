"""This moudle implements statistics data formatting functionality.
"""
import pandas as pd

class DataFormatter:
    """Transforms data frames from format generated by sparse cluster to formats needed by the plotters.
    """
    def count_offload_task_client_statistics_legacy(self, df, start_at = 0.0, period_length = -1.0):
        """Transforms statistics data to appropriate format for plotting.
        """
        df = df.rename(columns={ 'processing_started':'request_sent_at',
                                 'latency': 'Latency (ms)',
                                 'node_id': 'connection_id',
                                 'offload_latency': 'Offload latency (ms)' })

        # Scale latencies to milliseconds
        df['Latency (ms)'] = df['Latency (ms)'].apply(lambda x: 1000.0*x)
        df['Offload latency (ms)'] = df['Offload latency (ms)'].apply(lambda x: 1000.0*x)

        # Drop first rows to ignore 'slow start'
        # (See e.g: https://stackoverflow.com/questions/64420777/opencv-cuda-api-very-slow-at-the-first-call)
        df = df[df["request_sent_at"] >= start_at]
        if period_length > 0.0:
            df = df[df["request_sent_at"] <= start_at + period_length]
        df["request_sent_at"] = df["request_sent_at"].apply(lambda x: x-start_at)

        return df.set_index("request_sent_at")

    def to_runtime_latency(self, df, start_at = None, period_length = None):
        """Calculates latencies from a Dataframe with time stamps, and returns a new DataFrame with the results.

        Result DataFrame uses 'request_sent_at' timestamp as the index.
        """
        df['queueing_latency'] = df['input_dispatched_at'] - df['input_buffered_at']
        df['processing_latency'] = df['result_received_at'] - df['input_dispatched_at']

        # Scale latencies to milliseconds
        df['queueing_latency'] = df['queueing_latency'].apply(lambda x: 1000.0*x)
        df['processing_latency'] = df['processing_latency'].apply(lambda x: 1000.0*x)

        if start_at is not None:
            df = df[df["input_buffered_at"] >= start_at]
        if period_length is not None:
            df = df[df["input_buffered_at"] <= start_at + period_length]

        # Use the first task start as the time origo
        first_input_buffered_at = df["input_buffered_at"][0]
        df["input_buffered_at"] = df["input_buffered_at"].apply(lambda x: x-first_input_buffered_at)

        df = df.drop(columns=["operator_id", "input_dispatched_at", "result_received_at"])

        return df.set_index("input_buffered_at")

    def group_by_no_sources(self, df):
        """Groups dataframe by the number of distinct source streams.
        """
        len(pd.unique(df["source_stream_id"]))
        return df.assign(no_sources=len(pd.unique(df["source_stream_id"])), scheduling="pause-frames")

    def group_by_batch_size(self, df):
        """Groups dataframe by the number of distinct source streams.
        """
        # TODO: add batch number to runtime statistics records.
        return df.assign(batch_size=20)

    def count_offload_task_server_statistics(self, df, start_at = 0.0, period_length = -1.0):
        """Transforms server task statistics into appropriate format for plotting.
        """
        df = df.loc[df['request_op']=='offload_task']

        df['e2e_latency'] = df['response_sent_at'] - df['request_received_at']
        df['rx_latency'] = df['task_queued_at'] - df['request_received_at']
        df['queueing_time'] = df['task_started_at'] - df['task_queued_at']
        df['task_latency'] = df['task_completed_at'] - df['task_started_at']
        df['tx_latency'] = df['response_sent_at'] - df['task_completed_at']

        # Scale latencies to milliseconds
        for column in ['e2e_latency', 'rx_latency', 'queueing_time', 'task_latency', 'tx_latency']:
            df[column] = df[column].apply(lambda x: 1000.0*x)

        # Rename columns
        df = df.rename(columns={ 'e2e_latency': 'Service time (ms)',
                                 'rx_latency': 'RX latency (ms)',
                                 'queueing_time': 'Queueing time (ms)',
                                 'task_latency': 'Task latency (ms)',
                                 'tx_latency': 'TX latency (ms)' })

        # Translate time axis
        df = df[df["request_received_at"] >= start_at]
        if period_length > 0.0:
            df = df[df["request_received_at"] <= start_at + period_length]
        df["request_received_at"] = df["request_received_at"].apply(lambda x: x-start_at)

        return df.set_index("request_received_at")

    def count_offload_task_server_batch_statistics(self, \
                                                   df, \
                                                   operator_name : str, \
                                                   start_at = None, \
                                                   period_length = -1.0):
        """Transforms server batch statistics into appropriate format for plotting.
        """
        df = df.loc[df['operator_name']==operator_name]

        if start_at is not None:
            df = df[df["task_started_at"] >= start_at]

        if period_length > 0.0:
            df = df[df["task_started_at"] <= start_at + period_length]

        result_df = pd.DataFrame([], columns=["Task started (s)", "Task latency (ms)", "Batch Size"])

        batch_size = task_started = task_latency = 0
        batch_no = -1
        for i in df.index:
            if df["batch_no"][i] == batch_no:
                batch_size += 1
            else:
                if batch_size > 0:
                    result_df.loc[len(result_df.index)] = [task_started, task_latency, batch_size]
                batch_no = df["batch_no"][i]

                task_started = df["task_started_at"][i]
                task_latency = 1000.0 * (df["task_completed_at"][i] - df["task_started_at"][i])
                batch_size = 1

        result_df["Task started (s)"] = result_df["Task started (s)"].apply(lambda x: x-start_at)
        return result_df.set_index("Task started (s)")
